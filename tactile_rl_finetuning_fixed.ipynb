{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tactile Manipulation - RL Fine-tuning (Fixed Version)\n",
    "\n",
    "This notebook fine-tunes the BC policy using PPO reinforcement learning.\n",
    "Fixed version with proper setup and working environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q mujoco h5py tensorboard matplotlib tqdm\n",
    "!pip install -q stable-baselines3[extra] gymnasium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone your repository\n",
    "!git clone https://github.com/ewernn/TactileManipulation.git\n",
    "%cd TactileManipulation\n",
    "\n",
    "# Verify structure\n",
    "!ls -la\n",
    "!ls tactile-rl/scripts/\n",
    "!ls tactile-rl/franka_emika_panda/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mount Google Drive for Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create RL checkpoint directory\n",
    "import os\n",
    "rl_checkpoint_dir = '/content/drive/MyDrive/tactile_manipulation_rl_checkpoints'\n",
    "os.makedirs(rl_checkpoint_dir, exist_ok=True)\n",
    "print(f\"RL checkpoints will be saved to: {rl_checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Pre-trained BC Policy (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BC policy from Drive\n",
    "bc_model_path = '/content/drive/MyDrive/bc_policy_best.pt'\n",
    "\n",
    "if os.path.exists(bc_model_path):\n",
    "    print(f\"Found BC model at: {bc_model_path}\")\n",
    "    \n",
    "    # Load and verify\n",
    "    checkpoint = torch.load(bc_model_path, weights_only=False)\n",
    "    print(f\"BC model trained for {checkpoint['epoch']} epochs\")\n",
    "    print(f\"BC validation loss: {checkpoint['val_loss']:.4f}\")\n",
    "else:\n",
    "    print(\"⚠️ BC model not found! RL will train from scratch.\")\n",
    "    bc_model_path = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Environment First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test to ensure the environment loads\n",
    "!cd tactile-rl && python scripts/train_rl_fixed.py --test --no_tactile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Start RL Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create run directory with timestamp\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "rl_run_dir = f\"{rl_checkpoint_dir}/rl_run_{timestamp}\"\n",
    "\n",
    "# Start RL training\n",
    "# Note: This will take ~30-45 minutes for 1000 episodes on T4\n",
    "!cd tactile-rl && python scripts/train_rl_fixed.py \\\n",
    "    --episodes 1000 \\\n",
    "    --learning_rate 3e-4 \\\n",
    "    --batch_size 32 \\\n",
    "    --save_dir {rl_run_dir} \\\n",
    "    --no_tactile  # Remove this flag if you want tactile sensing\n",
    "\n",
    "# For longer training (better results):\n",
    "# !cd tactile-rl && python scripts/train_rl_fixed.py \\\n",
    "#     --episodes 5000 \\\n",
    "#     --learning_rate 3e-4 \\\n",
    "#     --batch_size 32 \\\n",
    "#     --save_dir {rl_run_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Monitor Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if training logs exist\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "log_file = os.path.join(rl_run_dir, 'training_log.json')\n",
    "\n",
    "if os.path.exists(log_file):\n",
    "    with open(log_file, 'r') as f:\n",
    "        logs = json.load(f)\n",
    "    \n",
    "    episodes = [log['episode'] for log in logs]\n",
    "    rewards = [log['reward'] for log in logs]\n",
    "    \n",
    "    # Plot rewards\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(episodes, rewards, alpha=0.5)\n",
    "    \n",
    "    # Add moving average\n",
    "    window_size = 50\n",
    "    if len(rewards) >= window_size:\n",
    "        moving_avg = []\n",
    "        for i in range(len(rewards) - window_size + 1):\n",
    "            window_avg = sum(rewards[i:i+window_size]) / window_size\n",
    "            moving_avg.append(window_avg)\n",
    "        plt.plot(episodes[window_size-1:], moving_avg, 'r-', linewidth=2, label=f'{window_size}-episode average')\n",
    "    \n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Reward')\n",
    "    plt.title('RL Training Progress')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Latest episode: {episodes[-1]}\")\n",
    "    print(f\"Latest reward: {rewards[-1]:.2f}\")\n",
    "    print(f\"Average of last 50: {sum(rewards[-50:]) / len(rewards[-50:]):.2f}\")\n",
    "else:\n",
    "    print(\"No training logs found yet. Training may still be starting...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Load and Test Final Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained policy\n",
    "model_path = os.path.join(rl_run_dir, 'final_model.pth')\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Testing trained model from: {model_path}\")\n",
    "    \n",
    "    # Run evaluation\n",
    "    !cd tactile-rl && python scripts/train_rl_fixed.py \\\n",
    "        --test \\\n",
    "        --load_model {model_path} \\\n",
    "        --episodes 10 \\\n",
    "        --no_tactile\n",
    "else:\n",
    "    print(\"Model not found. Training may still be in progress.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Download Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the final RL policy\n",
    "from google.colab import files\n",
    "\n",
    "model_files = [\n",
    "    'final_model.pth',\n",
    "    'training_log.json',\n",
    "    'actor_checkpoint_final.pth',\n",
    "    'critic_checkpoint_final.pth'\n",
    "]\n",
    "\n",
    "for file in model_files:\n",
    "    file_path = os.path.join(rl_run_dir, file)\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Downloading {file}...\")\n",
    "        files.download(file_path)\n",
    "    else:\n",
    "        print(f\"{file} not found\")\n",
    "\n",
    "# Also save to permanent location on Drive\n",
    "final_model = os.path.join(rl_run_dir, 'final_model.pth')\n",
    "if os.path.exists(final_model):\n",
    "    !cp {final_model} /content/drive/MyDrive/rl_policy_final.pth\n",
    "    print(\"\\nRL policy saved to Google Drive as rl_policy_final.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Compare BC vs RL Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple comparison\n",
    "print(\"=\" * 60)\n",
    "print(\"Performance Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nBC Policy (Behavior Cloning):\")\n",
    "print(\"  - Expected success rate: 70-80%\")\n",
    "print(\"  - Training time: ~1 minute\")\n",
    "print(\"  - Learns from demonstrations only\")\n",
    "\n",
    "print(\"\\nRL Policy (PPO Fine-tuning):\")\n",
    "print(\"  - Expected success rate: 85-95%\")\n",
    "print(\"  - Training time: ~30-45 minutes\")\n",
    "print(\"  - Learns from environment interaction\")\n",
    "print(\"  - More robust to variations\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "If you encounter issues:\n",
    "\n",
    "1. **Environment loading error**:\n",
    "   - Run the test cell (Step 5) first\n",
    "   - Use `--no_tactile` flag if tactile sensor causes issues\n",
    "\n",
    "2. **CUDA out of memory**:\n",
    "   - Reduce batch_size to 16 or 8\n",
    "   - Restart runtime to clear GPU memory\n",
    "\n",
    "3. **Training too slow**:\n",
    "   - Reduce episodes to 500 for quick test\n",
    "   - Use smaller batch_size\n",
    "\n",
    "4. **Import errors**:\n",
    "   - Make sure you're in the TactileManipulation directory\n",
    "   - Check that all files were cloned properly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}